<div align="center">
  <img src="./image/title.png" width="800" />
</div>
<div align="center">
<strong>汇总最新的LLM和VLM！帮助您便捷、快速地挑选和使用大模型！😄</strong><br>
<strong>当前为仓库导航页面，Awesome List正文：<a href="./README_LLM.md">LLMs🚀</a></strong> | <strong><a href="./README_VLMs.md">VLMs🚀</a></strong><br>
<strong>支持语言：中文</strong> | <strong><a href="./README.md">English🚀</a></strong>
</div>

欢迎来到我们的仓库🌐✨，这是一个全面的导航页面，连接您到最新的大模型（包括大型语言模型 <a href="./README_LLM.md">LLMs🚀</a> 和视觉语言模型 <a href="./README_VLMs.md">VLMs🚀</a>）的最相关资源和总结平台。无论您是在寻找基准测试、比较还是调查，我们都能满足您的需求。**这个导航页面还链接到其他相关的总结平台**。请探索以下各部分，找到您需要的信息：

- [大语言模型（LLM）的推理速度基准测试🚀](#大语言模型llm推理速度基准测试)
- [大语言模型（LLM）的综合分析和比较🔍](#大语言模型llm的综合分析和比较)
- [大语言模型（LLM）响应时间的可靠测量⏱️](#大语言模型llm响应时间的可靠测量)
- [VLM综合调研📊](#vlm综合调研 )。



## 大语言模型（LLM）推理速度基准测试🚀

[GPU-Benchmarks-on-LLM-Inference](https://github.com/XiongjieDai/GPU-Benchmarks-on-LLM-Inference)使用多种NVIDIA GPU和Apple Silicon设备，通过llama.cpp工具测试LLaMA 3等模型，在不同硬件配置下测量性能（通过每秒生成的tokens数量展示性能）。涵盖NVIDIA 3000、4000和A100系列，以及Apple的M1、M2和M3芯片。



## 大语言模型（LLM）的综合分析和比较🔍

网站 [LifeArchitect.ai/models](https://lifearchitect.ai/models) 提供对大型语言模型（LLM）的综合分析和比较，包括GPT-3、GPT-4、PaLM等多个模型，具体涉及这些模型的规模、能力和训练数据。



## 大语言模型（LLM）响应时间的可靠测量⏱️

[TheFastest.ai]([TheFastest.ai](https://thefastest.ai/)) 提供流行大型语言模型（LLMs）性能的可靠测量数据（基于响应时间）。它比较了不同模型在多个数据中心（如美国西部、西东和欧洲）的响应速度，主要指标包括首次响应时间（TTFT）和每秒生成的tokens数量（TPS）。网站评估的重点是模型的推理速度，并**每日更新统计数据**。



## VLM综合调研📊

[VLM_survey](https://github.com/jingyi0000/VLM_survey)是由最新的VLMs的汇总和调查组织而成的存储库，汇总了以下几个方面的内容，并给出相应的论文链接。

1. **视觉语言模型综述**：回顾了在图像分类、目标检测、语义分割等视觉识别任务中，VLMs的研究。

2. **预训练方法**：总结了VLM的网络架构、预训练目标和下游任务。

3. **迁移学习方法**：介绍了VLM在不同任务中的迁移学习策略。

4. **知识蒸馏方法**：讨论了VLM在目标检测、语义分割等任务中的知识蒸馏技术。
